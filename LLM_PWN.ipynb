{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\" In the last update, we have included several new features and enhancements to improve user experience and functionality:\\n\\n1. New Dashboard Design: We've refreshed the dashboard design with a modern look that makes it easier for users to navigate and find the information they need.\\n2. Enhanced Data Visualization: The updated platform now offers more powerful data visualization tools, allowing users to better understand their data and make informed decisions based on insights.\\n3. Expanded Integration Options: We've added new integration options with popular third-party applications, making it simpler for users to connect their favorite tools and streamline workflows.\\n4. Improved Performance and Speed: Our team has worked on optimizing the platform to ensure faster load times and smoother performance, even when handling large data sets.\\n5. New Learning Resources: To help users get the most out of our platform, we've added new learning resources such as tutorials, webinars, and guides that cover various aspects of the software.\\n6. Security Enhancements: We've implemented additional security measures to protect user data and ensure a safe and secure environment for all users.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"model-identifier\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in correct and detailed\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please summarize the key points from your last update or training data inclusion.\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=' As an AI language model, I do not have a specific context or personal experiences. However, I am trained on vast amounts of text data to understand natural language and provide accurate responses based on that understanding. My goal is to assist users with information, answers, or explanations to their questions, while adhering to the guidelines and rules provided by my creators.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"model-identifier\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in correct and detailed\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is your context information?\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=' Yes, I have heard of Clinical Quality Language (CQL). CQL is a domain-specific language used to define rules and logic for processing clinical data in healthcare systems. In the example you provided, `Patient.birthDate` is an object or attribute within CQL that represents the date of birth of the patient.\\n\\nTo give some context on how it might be used:\\n\\n```yaml\\nGiven Patient \"p\" and their attributes:\\n\\nIf p.hasAttribute(\"birthDate\") Then\\n    Let birthDate = p.getAttribute(\"birthDate\")\\n    If birthDate > 1960-01-01 And birthDate < 2000-01-01 Then\\n        Do something...\\n```\\n\\nIn this example, we\\'re checking if the patient has a `birthDate` attribute and if it falls within certain date ranges. Depending on the result of these checks, some action or processing might be performed.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"model-identifier\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in correct and detailed\"},\n",
    "    {\"role\": \"user\", \"content\": \"have you heard of Clinical Quality Language (CQL) output \\n\\n```yaml\\nPatient.birthDate\\n```\\n\\n\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
